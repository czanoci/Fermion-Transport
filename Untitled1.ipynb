{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVj0EYT4Rv1s1SfF7I/SRw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ATSM EM Iterative Fit"
      ],
      "metadata": {
        "id": "U8lrJ5Ex6eGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "from scipy.linalg import expm\n",
        "from statsmodels.tsa.statespace.kalman_filter import KalmanFilter\n",
        "from statsmodels.tsa.statespace.kalman_smoother import KalmanSmoother\n",
        "from statsmodels.tsa.statespace.mlemodel import MLEModel\n",
        "\n",
        "# -----------------------\n",
        "# Utility Functions\n",
        "# -----------------------\n",
        "def discretize_kalman(K, theta, Sigma, dt):\n",
        "    Phi = expm(-K * dt)\n",
        "    c = (np.eye(K.shape[0]) - Phi) @ theta\n",
        "    Q = Sigma @ Sigma.T * dt  # Approximate discrete covariance\n",
        "    return Phi, c, Q\n",
        "\n",
        "def riccati_solve(K_q, theta_q, Sigma, tau):\n",
        "    B_tau = np.linalg.solve(K_q.T, (np.eye(K_q.shape[0]) - expm(-K_q.T * tau))) @ np.ones(K_q.shape[0])\n",
        "    A_tau = -0.5 * tau * np.dot(B_tau, Sigma @ Sigma.T @ B_tau)\n",
        "    return A_tau, B_tau\n",
        "\n",
        "# -----------------------\n",
        "# Custom Statsmodels LGSSM Class\n",
        "# -----------------------\n",
        "class AffineLGSSM(MLEModel):\n",
        "    def __init__(self, yields, maturities, K_q, theta_q, Sigma):\n",
        "        n_obs = yields.shape[1]\n",
        "        k_states = Sigma.shape[0]\n",
        "        super().__init__(yields, k_states=k_states, initialization='approximate_diffuse')\n",
        "\n",
        "        self.K_q = K_q\n",
        "        self.theta_q = theta_q\n",
        "        self.Sigma = Sigma\n",
        "        self.maturities = maturities\n",
        "\n",
        "        self['design'] = np.zeros((n_obs, k_states))\n",
        "        self['obs_intercept'] = np.zeros(n_obs)\n",
        "        self['transition'] = np.eye(k_states)\n",
        "        self['state_intercept'] = np.zeros(k_states)\n",
        "        self['selection'] = np.eye(k_states)\n",
        "        self['state_cov'] = np.eye(k_states)\n",
        "        self['obs_cov'] = 0.01 * np.eye(n_obs)\n",
        "\n",
        "    def update_model_matrices(self, K_p, theta_p):\n",
        "        Phi, c, Q = discretize_kalman(K_p, theta_p, self.Sigma, dt=1.0)\n",
        "        A_mat = np.zeros(len(self.maturities))\n",
        "        B_mat = np.zeros((len(self.maturities), self.k_states))\n",
        "        for i, tau in enumerate(self.maturities):\n",
        "            A_mat[i], B_mat[i] = riccati_solve(self.K_q, self.theta_q, self.Sigma, tau)\n",
        "\n",
        "        self['transition'] = Phi\n",
        "        self['state_intercept'] = c\n",
        "        self['state_cov'] = Q\n",
        "        self['design'] = B_mat\n",
        "        self['obs_intercept'] = A_mat\n",
        "\n",
        "# -----------------------\n",
        "# EM Algorithm Using Statsmodels\n",
        "# -----------------------\n",
        "def em_fit_p_dynamics(yields, maturities, K_q, theta_q, Sigma, lambda_0, lambda_1, max_iter=10):\n",
        "    d = K_q.shape[0]\n",
        "    K_p = K_q + Sigma @ lambda_1\n",
        "    theta_p = np.linalg.solve(K_p, K_q @ theta_q - Sigma @ lambda_0)\n",
        "\n",
        "    model = AffineLGSSM(yields, maturities, K_q, theta_q, Sigma)\n",
        "    loglikelihoods = []\n",
        "    smoothed_states = []\n",
        "\n",
        "    for iteration in range(max_iter):\n",
        "        model.update_model_matrices(K_p, theta_p)\n",
        "        smoothed = model.smooth([])\n",
        "\n",
        "        # Store log-likelihood\n",
        "        loglikelihoods.append(model.loglike())\n",
        "\n",
        "        # Store smoothed states\n",
        "        smoothed_states.append(smoothed.smoothed_state.T.copy())\n",
        "\n",
        "        covs = smoothed.smoothed_state_cov\n",
        "        cross_covs = smoothed.smoothed_state_cov_all[:, :, 1:]\n",
        "\n",
        "        Sxx = np.sum(covs[:, :, :-1], axis=2)\n",
        "        Syx = np.sum(cross_covs, axis=2)\n",
        "\n",
        "        Phi_new = Syx @ np.linalg.inv(Sxx)\n",
        "        X = smoothed.smoothed_state.T\n",
        "        c_new = X[1:].mean(axis=0) - Phi_new @ X[:-1].mean(axis=0)\n",
        "\n",
        "        # Estimate Q\n",
        "        residuals = X[1:] - (X[:-1] @ Phi_new.T + c_new)\n",
        "        Q = (residuals.T @ residuals) / (len(X) - 1)\n",
        "        Sigma = np.linalg.cholesky(Q)\n",
        "\n",
        "        # Update continuous-time parameters\n",
        "        K_p = -np.log(Phi_new)\n",
        "        theta_p = np.linalg.solve(np.eye(d) - Phi_new, c_new)\n",
        "\n",
        "    return K_p, theta_p, Sigma, loglikelihoods, smoothed_states[-1]\n",
        "\n",
        "# -----------------------\n",
        "# Step 2: Fit Q-measure Dynamics\n",
        "# -----------------------\n",
        "def fit_q_dynamics(yield_curves, X_t_hist, maturities):\n",
        "    d = X_t_hist.shape[1]\n",
        "\n",
        "    def objective(Ktheta_flat):\n",
        "        K_q = Ktheta_flat[:d*d].reshape(d, d)\n",
        "        theta_q = Ktheta_flat[d*d:].reshape(d)\n",
        "        error = 0.0\n",
        "        for t, yields_t in enumerate(yield_curves):\n",
        "            for i, tau in enumerate(maturities):\n",
        "                A_tau, B_tau = riccati_solve(K_q, theta_q, Sigma=np.eye(d), tau=tau)\n",
        "                y_model = A_tau + B_tau @ X_t_hist[t]\n",
        "                error += (yields_t[i] - y_model) ** 2\n",
        "        return error\n",
        "\n",
        "    init_K = 0.05 * np.eye(d).flatten()\n",
        "    init_theta = np.zeros(d)\n",
        "    init_params = np.concatenate([init_K, init_theta])\n",
        "    res = minimize(objective, init_params, method='L-BFGS-B')\n",
        "    K_q = res.x[:d*d].reshape(d, d)\n",
        "    theta_q = res.x[d*d:]\n",
        "    return K_q, theta_q\n",
        "\n",
        "# -----------------------\n",
        "# Master Loop\n",
        "# -----------------------\n",
        "def fit_affine_term_structure(yield_curves, X_t_hist, maturities, max_iter=10):\n",
        "    d = X_t_hist.shape[1]\n",
        "    K_q = 0.05 * np.eye(d)\n",
        "    theta_q = np.zeros(d)\n",
        "    Sigma = np.eye(d)\n",
        "    lambda_0 = np.zeros(d)\n",
        "    lambda_1 = np.zeros((d, d))\n",
        "\n",
        "    for iter in range(max_iter):\n",
        "        print(f\"Iteration {iter + 1}\")\n",
        "        K_p, theta_p, Sigma, logliks, X_t_hist = em_fit_p_dynamics(\n",
        "            yield_curves, maturities, K_q, theta_q, Sigma, lambda_0, lambda_1\n",
        "        )\n",
        "        K_q, theta_q = fit_q_dynamics(yield_curves, X_t_hist, maturities)\n",
        "        print(f\"  Log-likelihood: {logliks[-1]:.2f}\")\n",
        "\n",
        "    return K_p, theta_p, K_q, theta_q, lambda_0, lambda_1, Sigma, X_t_hist"
      ],
      "metadata": {
        "id": "C5g18H2-6NKO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ATSM MLE Iterative Fit"
      ],
      "metadata": {
        "id": "RN0wza0i6vCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "from scipy.linalg import expm, solve_continuous_lyapunov\n",
        "\n",
        "# -----------------------\n",
        "# Utility Functions\n",
        "# -----------------------\n",
        "def discretize_kalman(K, theta, Sigma, dt):\n",
        "    \"\"\"Discretize continuous-time Ornstein-Uhlenbeck process\"\"\"\n",
        "    Phi = expm(-K * dt)\n",
        "    c = (np.eye(K.shape[0]) - Phi) @ theta\n",
        "    Q = solve_continuous_lyapunov(K, Sigma @ Sigma.T) * dt  # crude approx\n",
        "    return Phi, c, Q\n",
        "\n",
        "def riccati_solve(K_q, theta_q, Sigma, tau):\n",
        "    \"\"\"Compute A(tau), B(tau) via simplified Riccati (placeholder)\"\"\"\n",
        "    # This is a stub: replace with full Riccati ODE solver\n",
        "    B_tau = np.linalg.solve(K_q.T, (np.eye(K_q.shape[0]) - expm(-K_q.T * tau))) @ np.ones(K_q.shape[0])\n",
        "    A_tau = -0.5 * tau * np.dot(B_tau, Sigma @ Sigma.T @ B_tau)  # crude\n",
        "    return A_tau, B_tau\n",
        "\n",
        "# -----------------------\n",
        "# Step 1: Fit P-measure Dynamics\n",
        "# -----------------------\n",
        "def fit_p_dynamics(yields, maturities, X_t_hist, K_q, theta_q, Sigma):\n",
        "    d = K_q.shape[0]\n",
        "\n",
        "    def objective(lambda_vec):\n",
        "        lambda_0 = lambda_vec[:d]\n",
        "        lambda_1 = lambda_vec[d:].reshape(d, d)\n",
        "        K_p = K_q + Sigma @ lambda_1\n",
        "        theta_p = np.linalg.solve(K_p, K_q @ theta_q - Sigma @ lambda_0)\n",
        "        # Discretize\n",
        "        Phi, c, Q = discretize_kalman(K_p, theta_p, Sigma, dt=1.0)\n",
        "\n",
        "        # Forecast and compute error\n",
        "        error = 0.0\n",
        "        X_pred = X_t_hist[0]\n",
        "        for t in range(1, len(X_t_hist)):\n",
        "            X_pred = Phi @ X_pred + c\n",
        "            error += np.sum((X_pred - X_t_hist[t]) ** 2)\n",
        "        return error\n",
        "\n",
        "    init_lambda = np.zeros(d + d * d)\n",
        "    res = minimize(objective, init_lambda, method='L-BFGS-B')\n",
        "    lambda_opt = res.x\n",
        "    lambda_0 = lambda_opt[:d]\n",
        "    lambda_1 = lambda_opt[d:].reshape(d, d)\n",
        "    K_p = K_q + Sigma @ lambda_1\n",
        "    theta_p = np.linalg.solve(K_p, K_q @ theta_q - Sigma @ lambda_0)\n",
        "    return K_p, theta_p, lambda_0, lambda_1\n",
        "\n",
        "# -----------------------\n",
        "# Step 2: Fit Q-measure Dynamics\n",
        "# -----------------------\n",
        "def fit_q_dynamics(yield_curves, X_t_hist, maturities):\n",
        "    d = X_t_hist.shape[1]\n",
        "\n",
        "    def objective(Ktheta_flat):\n",
        "        K_q = Ktheta_flat[:d*d].reshape(d, d)\n",
        "        theta_q = Ktheta_flat[d*d:].reshape(d)\n",
        "        error = 0.0\n",
        "        for t, yields_t in enumerate(yield_curves):\n",
        "            for i, tau in enumerate(maturities):\n",
        "                A_tau, B_tau = riccati_solve(K_q, theta_q, Sigma=np.eye(d), tau=tau)\n",
        "                y_model = A_tau + B_tau @ X_t_hist[t]\n",
        "                error += (yields_t[i] - y_model) ** 2\n",
        "        return error\n",
        "\n",
        "    init_K = 0.05 * np.eye(d).flatten()\n",
        "    init_theta = np.zeros(d)\n",
        "    init_params = np.concatenate([init_K, init_theta])\n",
        "    res = minimize(objective, init_params, method='L-BFGS-B')\n",
        "    K_q = res.x[:d*d].reshape(d, d)\n",
        "    theta_q = res.x[d*d:]\n",
        "    return K_q, theta_q\n",
        "\n",
        "# -----------------------\n",
        "# Master Loop\n",
        "# -----------------------\n",
        "def fit_affine_term_structure(yield_curves, X_t_hist, maturities, max_iter=10):\n",
        "    d = X_t_hist.shape[1]\n",
        "    K_q = 0.05 * np.eye(d)\n",
        "    theta_q = np.zeros(d)\n",
        "    Sigma = np.eye(d)\n",
        "\n",
        "    for iter in range(max_iter):\n",
        "        print(f\"Iteration {iter + 1}\")\n",
        "        K_p, theta_p, lambda_0, lambda_1 = fit_p_dynamics(yield_curves, maturities, X_t_hist, K_q, theta_q, Sigma)\n",
        "        K_q, theta_q = fit_q_dynamics(yield_curves, X_t_hist, maturities)\n",
        "\n",
        "    return K_p, theta_p, K_q, theta_q, lambda_0, lambda_1"
      ],
      "metadata": {
        "id": "qcdfH_6w6NNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LGSSM EM"
      ],
      "metadata": {
        "id": "OeNe_CE68VJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.statespace.mlemodel import MLEModel\n",
        "\n",
        "class EM_LGSSM_Multivariate(MLEModel):\n",
        "    def __init__(self, endog, k_states):\n",
        "        \"\"\"\n",
        "        endog: array of shape (T, p) — observed time series (multivariate)\n",
        "        k_states: number of latent states\n",
        "        \"\"\"\n",
        "        endog = np.asarray(endog)\n",
        "        if endog.ndim == 1:\n",
        "            endog = endog[:, None]  # Convert to (T, 1) if univariate\n",
        "\n",
        "        self.T, self.p = endog.shape\n",
        "        self.k = k_states\n",
        "\n",
        "        super().__init__(endog, k_states=self.k, initialization='approximate_diffuse')\n",
        "\n",
        "        # Default initial system matrices\n",
        "        self.ssm['design'] = np.ones((self.p, self.k))     # C\n",
        "        self.ssm['transition'] = np.eye(self.k)            # A\n",
        "        self.ssm['selection'] = np.eye(self.k)             # Identity\n",
        "        self.ssm['state_cov'] = np.eye(self.k)             # Q\n",
        "        self.ssm['obs_cov'] = np.eye(self.p)               # R\n",
        "\n",
        "    def update_params(self, A, C, Q, R):\n",
        "        self.ssm['transition'] = A\n",
        "        self.ssm['design'] = C\n",
        "        self.ssm['state_cov'] = Q\n",
        "        self.ssm['obs_cov'] = R\n",
        "\n",
        "    def fit_em(self, num_iters=20, verbose=True):\n",
        "        T, p, k = self.T, self.p, self.k\n",
        "        y = self.endog\n",
        "\n",
        "        # Initialize parameters\n",
        "        A = np.eye(k)\n",
        "        C = np.random.randn(p, k)\n",
        "        Q = np.eye(k)\n",
        "        R = np.eye(p)\n",
        "\n",
        "        for it in range(num_iters):\n",
        "            self.update_params(A, C, Q, R)\n",
        "\n",
        "            # E-step: Kalman smoothing\n",
        "            smoother = self.ssm.smooth()\n",
        "            x_hat = smoother.smoothed_state.T          # (T, k)\n",
        "            P = smoother.smoothed_state_cov.T            # (T, k, k)\n",
        "            P_lag = smoother.smoothed_state_cov[:, :, :-1].T  # (T-1, k, k)\n",
        "\n",
        "            # Sufficient statistics\n",
        "            Ex = x_hat\n",
        "            Exx = P + np.einsum(\"ti,tj->tij\", Ex, Ex)\n",
        "            Exx_lag = P_lag + np.einsum(\"ti,tj->tij\", Ex[1:], Ex[:-1])\n",
        "\n",
        "            # --- M-step ---\n",
        "\n",
        "            # Update A\n",
        "            sum_Exx_lag = np.sum(Exx_lag, axis=0)\n",
        "            sum_Exx_tm1 = np.sum(Exx[:-1], axis=0)\n",
        "            A = sum_Exx_lag @ np.linalg.pinv(sum_Exx_tm1)\n",
        "\n",
        "            # Update Q\n",
        "            AQ = A @ sum_Exx_lag.T\n",
        "            Q = (np.sum(Exx[1:], axis=0) - AQ) / (T - 1)\n",
        "\n",
        "            # Update C\n",
        "            sum_yx = y.T @ Ex  # (p x k)\n",
        "            sum_xx = np.sum(Exx, axis=0)  # (k x k)\n",
        "            C = sum_yx @ np.linalg.pinv(sum_xx)\n",
        "\n",
        "            # Update R\n",
        "            residual = y - Ex @ C.T  # (T, p)\n",
        "            R = (residual.T @ residual) / T\n",
        "            for t in range(T):\n",
        "                R += C @ P[t] @ C.T / T\n",
        "\n",
        "            if verbose:\n",
        "                ll = smoother.llf\n",
        "                print(f\"Iteration {it + 1:2d}: log-likelihood = {ll:.2f}\")\n",
        "\n",
        "        self.update_params(A, C, Q, R)\n",
        "        return A, C, Q, R, smoother"
      ],
      "metadata": {
        "id": "QB3SaP3g6uaa"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "\n",
        "# Simulate multivariate LGSSM\n",
        "T = 200\n",
        "k = 2  # latent states\n",
        "p = 3  # observed dimensions\n",
        "\n",
        "A_true = np.array([[0.8, 0.1],\n",
        "                   [0.0, 0.9]])\n",
        "C_true = np.array([[1.0, 0.0],\n",
        "                   [0.5, 1.0],\n",
        "                   [0.0, 0.3]])\n",
        "Q_true = 0.1 * np.eye(k)\n",
        "R_true = 0.5 * np.eye(p)\n",
        "\n",
        "# Simulate latent states\n",
        "x = np.zeros((T, k))\n",
        "x[0] = np.random.randn(k)\n",
        "for t in range(1, T):\n",
        "    x[t] = A_true @ x[t - 1] + np.random.multivariate_normal(np.zeros(k), Q_true)\n",
        "\n",
        "# Simulate observations\n",
        "y = np.array([C_true @ x[t] + np.random.multivariate_normal(np.zeros(p), R_true) for t in range(T)])\n",
        "\n",
        "# Fit EM LGSSM\n",
        "model = EM_LGSSM_Multivariate(y, k_states=k)\n",
        "A_est, C_est, Q_est, R_est, smoother = model.fit_em(num_iters=30)\n",
        "\n",
        "print(\"\\nEstimated Parameters:\")\n",
        "print(\"A:\\n\", A_est)\n",
        "print(\"C:\\n\", C_est)\n",
        "print(\"Q:\\n\", Q_est)\n",
        "print(\"R:\\n\", R_est)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99sMYTSU6NQg",
        "outputId": "c2cdbaa6-5de1-4607-cb4e-d7eb07a5d4dc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration  1: log-likelihood = -1040.71\n",
            "Iteration  2: log-likelihood = -746.15\n",
            "Iteration  3: log-likelihood = -734.27\n",
            "Iteration  4: log-likelihood = -729.23\n",
            "Iteration  5: log-likelihood = -732.86\n",
            "Iteration  6: log-likelihood = -733.97\n",
            "Iteration  7: log-likelihood = -737.25\n",
            "Iteration  8: log-likelihood = -739.40\n",
            "Iteration  9: log-likelihood = -740.72\n",
            "Iteration 10: log-likelihood = -741.52\n",
            "Iteration 11: log-likelihood = -742.01\n",
            "Iteration 12: log-likelihood = -742.28\n",
            "Iteration 13: log-likelihood = -742.40\n",
            "Iteration 14: log-likelihood = -742.42\n",
            "Iteration 15: log-likelihood = -742.38\n",
            "Iteration 16: log-likelihood = -742.31\n",
            "Iteration 17: log-likelihood = -742.21\n",
            "Iteration 18: log-likelihood = -742.09\n",
            "Iteration 19: log-likelihood = -741.97\n",
            "Iteration 20: log-likelihood = -741.84\n",
            "Iteration 21: log-likelihood = -741.71\n",
            "Iteration 22: log-likelihood = -741.58\n",
            "Iteration 23: log-likelihood = -741.45\n",
            "Iteration 24: log-likelihood = -741.32\n",
            "Iteration 25: log-likelihood = -741.19\n",
            "Iteration 26: log-likelihood = -741.07\n",
            "Iteration 27: log-likelihood = -740.94\n",
            "Iteration 28: log-likelihood = -740.81\n",
            "Iteration 29: log-likelihood = -740.69\n",
            "Iteration 30: log-likelihood = -740.56\n",
            "\n",
            "Estimated Parameters:\n",
            "A:\n",
            " [[9.93293361e-01 3.78021275e-04]\n",
            " [2.45640739e-02 9.99200225e-01]]\n",
            "C:\n",
            " [[-0.48072323  0.05371691]\n",
            " [ 0.26389782 -0.09497754]\n",
            " [ 0.12061302 -0.024392  ]]\n",
            "Q:\n",
            " [[-0.00033087 -0.00040391]\n",
            " [-0.00040391  0.0009545 ]]\n",
            "R:\n",
            " [[0.74801093 0.09674595 0.00900227]\n",
            " [0.09674595 0.82678138 0.13994004]\n",
            " [0.00900227 0.13994004 0.49148152]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LGSSM EM + non-zero mean"
      ],
      "metadata": {
        "id": "M56Ml4POBLyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from statsmodels.tsa.statespace.mlemodel import MLEModel\n",
        "\n",
        "class EM_LGSSM_SingleLag(MLEModel):\n",
        "    def __init__(self, endog, k_states):\n",
        "        endog = np.asarray(endog)\n",
        "        if endog.ndim == 1:\n",
        "            endog = endog[:, None]\n",
        "        self.T, self.p = endog.shape\n",
        "        self.k = k_states\n",
        "\n",
        "        super().__init__(endog, k_states=self.k, initialization='approximate_diffuse')\n",
        "\n",
        "        self.ssm['transition'] = np.random.randn(self.k, self.k)\n",
        "        self.ssm['selection'] = np.eye(self.k)\n",
        "        self.ssm['state_cov'] = np.eye(self.k)\n",
        "        self.ssm['obs_cov'] = np.eye(self.p)\n",
        "        self.ssm['design'] = np.random.randn(self.p, self.k)\n",
        "\n",
        "        self.d = np.zeros((self.k, 1))  # state mean\n",
        "        self.c = np.zeros((self.p, 1))  # observation mean\n",
        "\n",
        "    def update_params(self, A, C, Q, R, d=None, c=None):\n",
        "        self.ssm['transition'] = A\n",
        "        self.ssm['design'] = C\n",
        "        self.ssm['state_cov'] = Q\n",
        "        self.ssm['obs_cov'] = R\n",
        "        self.d = d if d is not None else np.zeros((self.k, 1))\n",
        "        self.c = c if c is not None else np.zeros((self.p, 1))\n",
        "\n",
        "    def fit_em(self, num_iters=30, verbose=True):\n",
        "        T, p, k = self.T, self.p, self.k\n",
        "        y = self.endog\n",
        "\n",
        "        A = np.random.randn(k, k)\n",
        "        C = np.random.randn(p, k)\n",
        "        Q = np.eye(k)\n",
        "        R = np.eye(p)\n",
        "        d = np.zeros((k, 1))\n",
        "        c = np.zeros((p, 1))\n",
        "\n",
        "        for it in range(num_iters):\n",
        "            self.update_params(A, C, Q, R, d, c)\n",
        "            smoother = self.ssm.smooth()\n",
        "            x_hat = smoother.smoothed_state.T\n",
        "            P = smoother.smoothed_state_cov\n",
        "\n",
        "            x_centered = x_hat - d.T\n",
        "            y_centered = y - c.T\n",
        "\n",
        "            Exx = P[:T, :, :] + np.einsum('ti,tj->tij', x_hat, x_hat)\n",
        "\n",
        "            sum_yx = y_centered.T @ x_centered\n",
        "            sum_xx = np.sum(Exx, axis=0)\n",
        "            C = sum_yx @ np.linalg.pinv(sum_xx)\n",
        "\n",
        "            residual = y_centered - x_centered @ C.T\n",
        "            R = (residual.T @ residual) / T\n",
        "            for t in range(T):\n",
        "                R += C @ P[t] @ C.T / T\n",
        "\n",
        "            X_tm1 = x_hat[:-1]\n",
        "            X_t = x_hat[1:]\n",
        "            A = X_t.T @ X_tm1 @ np.linalg.pinv(X_tm1.T @ X_tm1 + np.sum(P[:-1], axis=0))\n",
        "\n",
        "            Q = np.zeros((k, k))\n",
        "            for t in range(1, T):\n",
        "                x_pred = d.flatten() + A @ (x_hat[t-1] - d.flatten())\n",
        "                err = x_hat[t] - x_pred\n",
        "                Q += np.outer(err, err)\n",
        "            Q /= (T - 1)\n",
        "\n",
        "            d = np.mean(x_hat, axis=0, keepdims=True).T\n",
        "            c = np.mean(y - x_hat @ C.T, axis=0, keepdims=True).T\n",
        "\n",
        "            if verbose:\n",
        "                ll = smoother.llf\n",
        "                print(f\"Iteration {it + 1:2d}: log-likelihood = {ll:.2f}\")\n",
        "\n",
        "        self.update_params(A, C, Q, R, d, c)\n",
        "        return A, C, Q, R, d, c, smoother"
      ],
      "metadata": {
        "id": "MRwVlaVzBKAI"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LGSSM EM Multilag"
      ],
      "metadata": {
        "id": "szn8Bh0J_k1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from statsmodels.tsa.statespace.mlemodel import MLEModel\n",
        "\n",
        "class EM_LGSSM_MultiLag(MLEModel):\n",
        "    def __init__(self, endog, k_states, lags):\n",
        "        \"\"\"\n",
        "        endog: array of shape (T, p) -- multivariate observed data\n",
        "        k_states: number of latent variables in original x_t\n",
        "        lags: number of lags L in the state transition equation\n",
        "        \"\"\"\n",
        "        endog = np.asarray(endog)\n",
        "        if endog.ndim == 1:\n",
        "            endog = endog[:, None]\n",
        "\n",
        "        self.T, self.p = endog.shape\n",
        "        self.k = k_states\n",
        "        self.L = lags\n",
        "        self.aug_k = self.k * self.L  # dimension of augmented state\n",
        "\n",
        "        super().__init__(endog, k_states=self.aug_k, initialization='approximate_diffuse')\n",
        "\n",
        "        # Initial system matrices\n",
        "        self.ssm['transition'] = np.zeros((self.aug_k, self.aug_k))\n",
        "        self.ssm['selection'] = np.eye(self.aug_k)\n",
        "        self.ssm['state_cov'] = np.eye(self.aug_k)\n",
        "        self.ssm['obs_cov'] = np.eye(self.p)\n",
        "        self.ssm['design'] = np.zeros((self.p, self.aug_k))\n",
        "        self.ssm['design'][:, :self.k] = np.random.randn(self.p, self.k)\n",
        "\n",
        "        # Transition blocks to be learned\n",
        "        self.A_blocks = [np.random.randn(self.k, self.k) for _ in range(self.L)]\n",
        "        self.update_transition_matrix()\n",
        "\n",
        "    def update_transition_matrix(self):\n",
        "        A_big = np.zeros((self.aug_k, self.aug_k))\n",
        "        # Top row blocks: A1, ..., AL\n",
        "        for i, A in enumerate(self.A_blocks):\n",
        "            A_big[:self.k, i*self.k:(i+1)*self.k] = A\n",
        "        # Shift identity blocks\n",
        "        for i in range(1, self.L):\n",
        "            A_big[i*self.k:(i+1)*self.k, (i-1)*self.k:i*self.k] = np.eye(self.k)\n",
        "        self.ssm['transition'] = A_big\n",
        "\n",
        "    def update_params(self, A_blocks, C, Q, R):\n",
        "        self.A_blocks = A_blocks\n",
        "        self.update_transition_matrix()\n",
        "        self.ssm['design'][:, :] = 0.0\n",
        "        self.ssm['design'][:, :self.k] = C\n",
        "        Q_aug = np.zeros((self.aug_k, self.aug_k))\n",
        "        Q_aug[:self.k, :self.k] = Q\n",
        "        self.ssm['state_cov'] = Q_aug\n",
        "        self.ssm['obs_cov'] = R\n",
        "\n",
        "    def fit_em(self, num_iters=30, verbose=True):\n",
        "        T, p, k, L = self.T, self.p, self.k, self.L\n",
        "        aug_k = self.aug_k\n",
        "        y = self.endog\n",
        "\n",
        "        # Initialize parameters\n",
        "        A_blocks = [np.random.randn(k, k) for _ in range(L)]\n",
        "        C = np.random.randn(p, k)\n",
        "        Q = np.eye(k)\n",
        "        R = np.eye(p)\n",
        "\n",
        "        for it in range(num_iters):\n",
        "            self.update_params(A_blocks, C, Q, R)\n",
        "            smoother = self.ssm.smooth()\n",
        "            z_hat = smoother.smoothed_state.T       # (T, aug_k)\n",
        "            P = smoother.smoothed_state_cov          # (T, aug_k, aug_k)\n",
        "            P_lag = smoother.smoothed_state_cov_state  # (T-1, aug_k, aug_k)\n",
        "\n",
        "            # Extract x_t (top block of z_t)\n",
        "            x_hat = z_hat[:, :k]  # (T, k)\n",
        "            Exx = P[:, :k, :k] + np.einsum('ti,tj->tij', x_hat, x_hat)\n",
        "\n",
        "            # --- Update C ---\n",
        "            sum_yx = y.T @ x_hat\n",
        "            sum_xx = np.sum(Exx, axis=0)\n",
        "            C = sum_yx @ np.linalg.pinv(sum_xx)\n",
        "\n",
        "            # --- Update R ---\n",
        "            residual = y - x_hat @ C.T\n",
        "            R = (residual.T @ residual) / T\n",
        "            for t in range(T):\n",
        "                R += C @ P[t, :k, :k] @ C.T / T\n",
        "\n",
        "            # --- Update A_blocks ---\n",
        "            Z = z_hat[:-1]  # z_{t-1}, shape (T-1, Lk)\n",
        "            Z_tp1 = z_hat[1:, :k]  # x_t = top k block of z_t, shape (T-1, k)\n",
        "            ZZ = np.einsum('ti,tj->tij', Z, Z)\n",
        "            ZY = np.einsum('ti,tj->tij', Z_tp1, Z)\n",
        "\n",
        "            A_concat = np.sum(ZY, axis=0) @ np.linalg.pinv(np.sum(ZZ, axis=0))  # (k, Lk)\n",
        "            A_blocks = [A_concat[:, i*k:(i+1)*k] for i in range(L)]\n",
        "\n",
        "            # --- Update Q ---\n",
        "            Q = np.zeros((k, k))\n",
        "            for t in range(1, T):\n",
        "                x_pred = sum(A_blocks[i] @ z_hat[t-1, i*k:(i+1)*k] for i in range(L))\n",
        "                err = z_hat[t, :k] - x_pred\n",
        "                Q += np.outer(err, err)\n",
        "            Q /= (T - 1)\n",
        "\n",
        "            if verbose:\n",
        "                ll = smoother.llf\n",
        "                print(f\"Iteration {it + 1:2d}: log-likelihood = {ll:.2f}\")\n",
        "\n",
        "        self.update_params(A_blocks, C, Q, R)\n",
        "        return A_blocks, C, Q, R, smoother"
      ],
      "metadata": {
        "id": "M7Z-PjhU8dJ9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LGSSM EM Multilag + non-zero mean"
      ],
      "metadata": {
        "id": "fzy6tCXH_qKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from statsmodels.tsa.statespace.mlemodel import MLEModel\n",
        "\n",
        "class EM_LGSSM_MultiLag(MLEModel):\n",
        "    def __init__(self, endog, k_states, lags):\n",
        "        endog = np.asarray(endog)\n",
        "        if endog.ndim == 1:\n",
        "            endog = endog[:, None]\n",
        "        self.T, self.p = endog.shape\n",
        "        self.k = k_states\n",
        "        self.L = lags\n",
        "        self.aug_k = self.k * self.L\n",
        "\n",
        "        super().__init__(endog, k_states=self.aug_k, initialization='approximate_diffuse')\n",
        "\n",
        "        self.ssm['transition'] = np.zeros((self.aug_k, self.aug_k))\n",
        "        self.ssm['selection'] = np.eye(self.aug_k)\n",
        "        self.ssm['state_cov'] = np.eye(self.aug_k)\n",
        "        self.ssm['obs_cov'] = np.eye(self.p)\n",
        "        self.ssm['design'] = np.zeros((self.p, self.aug_k))\n",
        "        self.ssm['design'][:, :self.k] = np.random.randn(self.p, self.k)\n",
        "\n",
        "        self.A_blocks = [np.random.randn(self.k, self.k) for _ in range(self.L)]\n",
        "        self.d = np.zeros((self.k, 1))  # state mean\n",
        "        self.c = np.zeros((self.p, 1))  # observation mean\n",
        "        self.update_transition_matrix()\n",
        "\n",
        "    def update_transition_matrix(self):\n",
        "        A_big = np.zeros((self.aug_k, self.aug_k))\n",
        "        for i, A in enumerate(self.A_blocks):\n",
        "            A_big[:self.k, i*self.k:(i+1)*self.k] = A\n",
        "        for i in range(1, self.L):\n",
        "            A_big[i*self.k:(i+1)*self.k, (i-1)*self.k:i*self.k] = np.eye(self.k)\n",
        "        self.ssm['transition'] = A_big\n",
        "\n",
        "    def update_params(self, A_blocks, C, Q, R, d=None, c=None):\n",
        "        self.A_blocks = A_blocks\n",
        "        self.update_transition_matrix()\n",
        "        self.ssm['design'][:, :] = 0.0\n",
        "        self.ssm['design'][:, :self.k] = C\n",
        "        Q_aug = np.zeros((self.aug_k, self.aug_k))\n",
        "        Q_aug[:self.k, :self.k] = Q\n",
        "        self.ssm['state_cov'] = Q_aug\n",
        "        self.ssm['obs_cov'] = R\n",
        "\n",
        "        self.d = d if d is not None else np.zeros((self.k, 1))\n",
        "        self.c = c if c is not None else np.zeros((self.p, 1))\n",
        "\n",
        "    def fit_em(self, num_iters=30, verbose=True):\n",
        "        T, p, k, L = self.T, self.p, self.k, self.L\n",
        "        aug_k = self.aug_k\n",
        "        y = self.endog\n",
        "\n",
        "        A_blocks = [np.random.randn(k, k) for _ in range(L)]\n",
        "        C = np.random.randn(p, k)\n",
        "        Q = np.eye(k)\n",
        "        R = np.eye(p)\n",
        "        d = np.zeros((k, 1))\n",
        "        c = np.zeros((p, 1))\n",
        "\n",
        "        for it in range(num_iters):\n",
        "            self.update_params(A_blocks, C, Q, R, d, c)\n",
        "            smoother = self.ssm.smooth()\n",
        "            z_hat = smoother.smoothed_state.T\n",
        "            P = smoother.smoothed_state_cov\n",
        "\n",
        "            x_hat = z_hat[:, :k]\n",
        "            Exx = P[:T, :k, :k] + np.einsum('ti,tj->tij', x_hat, x_hat)\n",
        "\n",
        "            y_centered = y - c.T\n",
        "            x_centered = x_hat - d.T\n",
        "\n",
        "            sum_yx = y_centered.T @ x_centered\n",
        "            sum_xx = np.sum(Exx, axis=0)\n",
        "            C = sum_yx @ np.linalg.pinv(sum_xx)\n",
        "\n",
        "            residual = y_centered - x_centered @ C.T\n",
        "            R = (residual.T @ residual) / T\n",
        "            for t in range(T):\n",
        "                R += C @ P[t, :k, :k] @ C.T / T\n",
        "\n",
        "            Z = z_hat[:-1]\n",
        "            Z_tp1 = z_hat[1:, :k]\n",
        "            ZZ = np.einsum('ti,tj->tij', Z, Z)\n",
        "            ZY = np.einsum('ti,tj->tij', Z_tp1 - d.T, Z)\n",
        "\n",
        "            A_concat = np.sum(ZY, axis=0) @ np.linalg.pinv(np.sum(ZZ, axis=0))\n",
        "            A_blocks = [A_concat[:, i*k:(i+1)*k] for i in range(L)]\n",
        "\n",
        "            Q = np.zeros((k, k))\n",
        "            for t in range(1, T):\n",
        "                x_pred = d.flatten()\n",
        "                for i in range(L):\n",
        "                    x_pred += A_blocks[i] @ z_hat[t-1, i*k:(i+1)*k]\n",
        "                err = z_hat[t, :k] - x_pred\n",
        "                Q += np.outer(err, err)\n",
        "            Q /= (T - 1)\n",
        "\n",
        "            d = np.mean(z_hat[:, :k], axis=0, keepdims=True).T\n",
        "            c = np.mean(y - x_hat @ C.T, axis=0, keepdims=True).T\n",
        "\n",
        "            if verbose:\n",
        "                ll = smoother.llf\n",
        "                print(f\"Iteration {it + 1:2d}: log-likelihood = {ll:.2f}\")\n",
        "\n",
        "        self.update_params(A_blocks, C, Q, R, d, c)\n",
        "        return A_blocks, C, Q, R, d, c, smoother"
      ],
      "metadata": {
        "id": "vBp1aunm_oj1"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4r6x9dcZ_z5x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}